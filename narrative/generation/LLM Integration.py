from narrative.generation.PromptManager import PromptManager

class LLMIntegration:
    """
    Manages the interaction between the narrative generation system and the Large Language Model (LLM).
    Responsible for sending prompts to the LLM and retrieving the generated text.
    """

    def __init__(self, narrative_structuring, context_manager):
        """
        Initializes the LLMIntegration with dependencies on narrative structuring and context management.

        Args:
            narrative_structuring (NarrativeStructuring): Handles the structure of the narrative.
            context_manager (ContextManager): Tracks narrative context to inform prompt construction.
        """
        self.prompt_manager = PromptManager(narrative_structuring, context_manager)
        self.llm_endpoint = self._initialize_llm_endpoint()

    def _initialize_llm_endpoint(self):
        """
        Initializes the connection to the LLM's API or local instance.

        Returns:
            str: The endpoint URL or connection details for the LLM.
        """
        # Placeholder for LLM initialization logic
        # Replace with actual LLM endpoint or connection setup
        return "https://api.llmservice.com/generate"

    def generate_narrative(self, scenario, character, current_state):
        """
        Generates narrative text by creating a prompt and sending it to the LLM.

        Args:
            scenario (str): The type of scenario (e.g., "dialogue", "action").
            character (Character): The character involved in the scenario.
            current_state (dict): The current state of the narrative, including location, recent actions, etc.

        Returns:
            str: The narrative text generated by the LLM.
        """
        # Use the PromptManager to create a prompt for the LLM
        prompt = self.prompt_manager.create_prompt(scenario, character, current_state)
        
        # Send the prompt to the LLM and retrieve the generated narrative
        narrative_text = self._send_prompt_to_llm(prompt)
        
        return narrative_text

    def _send_prompt_to_llm(self, prompt):
        """
        Sends the generated prompt to the LLM and retrieves the response.

        Args:
            prompt (str): The prompt generated by the PromptManager.

        Returns:
            str: The narrative text generated by the LLM.
        """
        # This is a placeholder for the actual API call or integration logic
        # You would typically use requests or another HTTP client to send the prompt
        # For example:
        # response = requests.post(self.llm_endpoint, json={"prompt": prompt})
        # return response.json().get('text', '')

        # Mock LLM response for demonstration purposes
        mock_response = f"LLM response based on prompt: {prompt}"
        return mock_response

    def adapt_prompt(self, base_prompt, tone=None, urgency=None):
        """
        Adapts a prompt by altering its tone or adding urgency before sending it to the LLM.

        Args:
            base_prompt (str): The base prompt to adapt.
            tone (str, optional): The desired tone (e.g., "serious", "lighthearted").
            urgency (str, optional): The urgency level (e.g., "urgent", "casual").

        Returns:
            str: The adapted prompt.
        """
        return self.prompt_manager.adapt_prompt(base_prompt, tone, urgency)
